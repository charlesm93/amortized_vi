{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE example\n",
    "Follow the tutorial on https://github.com/Jackson-Kang/Pytorch-VAE-tutorial which is for MNIST data; then adapt to FashionMNIST and CIFAR10 (for the latter optimization was slow and noisy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as dist\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '~/datasets'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load or download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options: MNIST, FashionMNIST, CIFAR10\n",
    "data_set = \"FashionMNIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000 # NOTE: use 10000 for MNIST and FashionMNIST\n",
    "\n",
    "if (data_set == \"MNIST\"):\n",
    "    x_dim = 784\n",
    "    hidden_dim = 400\n",
    "    latent_dim = 200\n",
    "\n",
    "if (data_set == \"CIFAR10\"):\n",
    "    x_dim = 32 * 32 * 3  # 3 color channels...\n",
    "    hidden_dim = 128\n",
    "    latent_dim = 100\n",
    "\n",
    "\n",
    "if (data_set == \"FashionMNIST\"):\n",
    "    x_dim = 28 * 28\n",
    "    # hidden_dim and latent_dim are specified later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (data_set == \"MNIST\"):\n",
    "        from torchvision.datasets import MNIST\n",
    "        import torchvision.transforms as transforms\n",
    "        from torch.utils.data import DataLoader\n",
    "\n",
    "        mnist_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "\n",
    "        train_dataset = MNIST(dataset_path, transform=mnist_transform, train=True, download=True)\n",
    "        test_dataset  = MNIST(dataset_path, transform=mnist_transform, train=False, download=True)\n",
    "\n",
    "if (data_set == \"CIFAR10\"):\n",
    "        from torchvision.datasets import CIFAR10\n",
    "        import torchvision.transforms as transforms\n",
    "        from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "        mnist_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "\n",
    "        train_dataset = CIFAR10(dataset_path, transform=mnist_transform, train=True, download=True)\n",
    "        test_dataset  = CIFAR10(dataset_path, transform=mnist_transform, train=False, download=True)\n",
    "\n",
    "\n",
    "if (data_set == \"FashionMNIST\"):\n",
    "        from torchvision.datasets import FashionMNIST\n",
    "        import torchvision.transforms as transforms\n",
    "        from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "        mnist_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "\n",
    "        train_dataset = FashionMNIST(dataset_path, transform=mnist_transform, train=True, download=True)\n",
    "        test_dataset  = FashionMNIST(dataset_path, transform=mnist_transform, train=False, download=True)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader  = DataLoader(dataset=test_dataset,  batch_size=batch_size, shuffle=False,  **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define target distribution and a variational family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_bias = True\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.FC_input = nn.Linear(input_dim, hidden_dim, bias = use_bias)\n",
    "        self.FC_input2 = nn.Linear(hidden_dim, hidden_dim, bias = use_bias)\n",
    "        self.FC_mean = nn.Linear(hidden_dim, latent_dim, bias = use_bias)\n",
    "        self.FC_sd_log = nn.Linear(hidden_dim, latent_dim, bias = use_bias)\n",
    "\n",
    "        self.LeakyRelu = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.training = True  # CHECK -- what does this line do?\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_ = self.LeakyRelu(self.FC_input(x))\n",
    "        h_ = self.LeakyRelu(self.FC_input2(h_))\n",
    "        mean = self.FC_mean(h_)\n",
    "        sd_log = self.FC_sd_log(h_)\n",
    "\n",
    "        return mean, sd_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_encoder(encoder, z_dim, hidden_dim, x_dim, nu_mean_z, nu_sd_z_log):\n",
    "    # Initialize A-VI at the output of a constant inference network.\n",
    "    encoder.FC_input.weights = nn.Parameter(torch.zeros(hidden_dim, x_dim)).to(device)\n",
    "    encoder.FC_input2.weights = nn.Parameter(torch.zeros(hidden_dim, hidden_dim)).to(device)\n",
    "    encoder.FC_mean.weights = nn.Parameter(torch.zeros(z_dim, hidden_dim)).to(device)\n",
    "    encoder.FC_sd_log.weights = nn.Parameter(torch.zeros(z_dim, hidden_dim)).to(device)\n",
    "\n",
    "    # encoder.FC_input.bias = nn.Parameter(torch.zeros(hidden_dim)).to(device)\n",
    "    # encoder.FC_input2.bias = nn.Parameter(torch.zeros(hidden_dim)).to(device)\n",
    "    encoder.FC_mean.bias = nn.Parameter(nu_mean_z)\n",
    "    encoder.FC_sd_log.bias = nn.Parameter(nu_sd_z_log)\n",
    "\n",
    "    return encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder_MNIST(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder_MNIST, self).__init__()\n",
    "        self.FC_hidden = nn.Linear(latent_dim, hidden_dim, bias = False)\n",
    "        self.FC_hidden2 = nn.Linear(hidden_dim, hidden_dim, bias = False)\n",
    "        self.FC_output = nn.Linear(hidden_dim, output_dim, bias = False)\n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "\n",
    "        # linear decoder\n",
    "        # self.FC_output = nn.Linear(latent_dim, output_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = self.LeakyReLU(self.FC_hidden(z))\n",
    "        h = self.LeakyReLU(self.FC_hidden2(h))\n",
    "        h = self.FC_output(h)\n",
    "\n",
    "        # linear decoder\n",
    "        # h = self.FC_output(z)\n",
    "\n",
    "        x_hat = torch.sigmoid(h)\n",
    "\n",
    "        return x_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_bias = False\n",
    "\n",
    "class Decoder_R(nn.Module):\n",
    "    # Uses a constrained Gaussian likelihood. Alternatively, we can use a Beta likelihood.\n",
    "    # (see commented out code).\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder_R, self).__init__()\n",
    "        self.FC_hidden = nn.Linear(latent_dim, hidden_dim, bias = use_bias)\n",
    "        self.FC_hidden2 = nn.Linear(hidden_dim, hidden_dim, bias = use_bias)\n",
    "        self.FC_alpha = nn.Linear(hidden_dim, output_dim, bias = use_bias)\n",
    "        # self.FC_beta = nn.Linear(hidden_dim, output_dim, bias = use_bias)\n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        h = self.LeakyReLU(self.FC_hidden(z))\n",
    "        h = self.LeakyReLU(self.FC_hidden2(h))\n",
    "\n",
    "        # NOTE: for Beta likelihood, we'll want to make alpha and beta positive\n",
    "        # alpha = self.FC_alpha(h)**2\n",
    "        # beta = self.FC_beta(h)**2\n",
    "\n",
    "        # NOTE: hack, use constrained gaussian likelihood\n",
    "        alpha = torch.sigmoid(self.FC_alpha(h))  # constrain mean between 0 and 1\n",
    "        # beta = self.FC_beta(h)**2  # constrain variance to be positive\n",
    "\n",
    "        return alpha  #, beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_weights_MNIST(decoder, theta, latent_dim, hidden_dim, x_dim):\n",
    "  with torch.no_grad():\n",
    "    # linear decoder\n",
    "    # decoder.FC_output.weight=\\\n",
    "    #   nn.Parameter(theta.reshape((x_dim, latent_dim)))\n",
    "    \n",
    "    ## Two-layers neural network\n",
    "\n",
    "    # Set the weights\n",
    "    index_layer1 = latent_dim * hidden_dim\n",
    "    decoder.FC_hidden.weight =\\\n",
    "        nn.Parameter(theta[:index_layer1].reshape((hidden_dim, latent_dim)))\n",
    "    \n",
    "    index_layer2 = index_layer1 + hidden_dim**2\n",
    "    decoder.FC_hidden2.weight =\\\n",
    "        nn.Parameter(theta[index_layer1:index_layer2].reshape((hidden_dim, hidden_dim)))\n",
    "    \n",
    "    index_output = index_layer2 + hidden_dim * x_dim\n",
    "    decoder.FC_output.weight =\\\n",
    "            nn.Parameter(theta[index_layer2:index_output].reshape((x_dim, hidden_dim)))\n",
    "    \n",
    "    # Set the biases\n",
    "    # index_bias1 = index_output + hidden_dim\n",
    "    # decoder.FC_hidden.bias =\\\n",
    "    #   nn.Parameter(torch.zeros(hidden_dim)).to(device)\n",
    "    #   # nn.Parameter(theta[index_output:index_bias1].reshape((hidden_dim)))\n",
    "    \n",
    "    # index_bias2 = index_bias1 + hidden_dim\n",
    "    # decoder.FC_hidden2.bias =\\\n",
    "    #   nn.Parameter(torch.zeros(hidden_dim)).to(device)\n",
    "    #   # nn.Parameter(theta[index_bias1:index_bias2].reshape((hidden_dim)))\n",
    "\n",
    "    # index_bias3 = index_bias2 + x_dim\n",
    "    # decoder.FC_output.bias =\\\n",
    "    #   nn.Parameter(torch.zeros(x_dim)).to(device)\n",
    "      # nn.Parameter(theta[index_bias2:index_bias3].reshape((x_dim)))  \n",
    "\n",
    "    return decoder\n",
    "\n",
    "\n",
    "def set_weights_R(decoder, theta, latent_dim, hidden_dim, x_dim):\n",
    "    # Set the weights\n",
    "    index_layer1 = latent_dim * hidden_dim\n",
    "    decoder.FC_hidden.weight =\\\n",
    "        nn.Parameter(theta[:index_layer1].reshape((hidden_dim, latent_dim)))\n",
    "    \n",
    "    index_layer2 = index_layer1 + hidden_dim**2\n",
    "    decoder.FC_hidden2.weight =\\\n",
    "        nn.Parameter(theta[index_layer1:index_layer2].reshape((hidden_dim, hidden_dim)))\n",
    "    \n",
    "    index_alpha = index_layer2 + hidden_dim * x_dim\n",
    "    decoder.FC_alpha.weight =\\\n",
    "            nn.Parameter(theta[index_layer2:index_alpha].reshape((x_dim, hidden_dim)))\n",
    "    \n",
    "    # NOTE: to mimic MSE, beta parameter (standard deviation) is set to 1\n",
    "    # index_beta = index_alpha + hidden_dim * x_dim\n",
    "    # decoder.FC_beta.weight =\\\n",
    "    #     nn.Parameter(theta[index_alpha:index_beta].reshape((x_dim, hidden_dim)))\n",
    "    \n",
    "    return decoder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: pytorch distributions don't seem to work cudas\n",
    "def bernoulli_lpmf(x, p):\n",
    "    eps = 1e-10\n",
    "    return torch.sum(x * torch.log(p + eps) + (1 - x) * torch.log(1 - p + eps),\n",
    "                                  dim = (1, 2))\n",
    "\n",
    "def gaussian_lpdf(x, mu, sigma_2):\n",
    "    return torch.sum( - 0.5 * torch.log(sigma_2) - 1 / (2 * sigma_2) * (x - mu)**2,\n",
    "                     dim = (1, 2))\n",
    "\n",
    "# NOTE: lgamma doesn't work on CUDA. Once this is fixed better to use Torch.distributions.\n",
    "def beta_lpdf(x, alpha, beta):\n",
    "    iid_components = torch.lgamma(alpha + beta) - torch.lgamma(alpha) - torch.lgamma(beta)\\\n",
    "        + (alpha - 1) * torch.log(x) + (beta - 1) * torch.log(1 - x)\n",
    "    return torch.sum(iid_components, dim = (1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized for GPU (the first index corresponds to the Monte Carlo sample)\n",
    "# the log_joint is computed over a batch of the data, rather than over the full data.\n",
    "def log_joint_MNIST(x, p, z, theta):\n",
    "    eps = 1e-10  # add jitter to stabilize cases where p is close to 0 or 1\n",
    "    like_weight = z.size()[1] / x.size()[0]\n",
    "    \n",
    "    return -0.5 * torch.sum(z**2, dim = (1, 2))\\\n",
    "           -0.5 * torch.sum(theta**2, dim = 1)\\\n",
    "        + like_weight * bernoulli_lpmf(x, p)\n",
    "\n",
    "def log_joint_R(x, alpha, beta, z, theta):\n",
    "    like_weight = z.size()[1] / x.size()[0]\n",
    "    # beta_dist = dist.beta.Beta(alpha, beta)\n",
    "    return -0.5 * torch.sum(z**2, dim = (1, 2))\\\n",
    "           -0.5 * torch.sum(theta**2, dim = 1)\\\n",
    "            + like_weight * gaussian_lpdf(x, alpha, beta)\n",
    "        # + like_weight *  torch.sum(beta_dist.log_prob(x), dim = (1, 2))\n",
    "        # + like_weight * gaussian_lpdf(x, alpha, beta)\n",
    "        # + like_weight * beta_lpdf(x, alpha, beta)\n",
    "        \n",
    "\n",
    "def log_q(theta, z, nu_mean_theta, nu_sd_theta_2, nu_mean_z, nu_sd_z_2):\n",
    "  log_q_theta = torch.sum(- 0.5 * torch.log(nu_sd_theta_2) - 1 / (2 * nu_sd_theta_2)\\\n",
    "                          * (theta - nu_mean_theta)**2, dim = (1))  # CHECK -- axis along which to sum\n",
    "  log_q_z = torch.sum(- 0.5 * torch.log(nu_sd_z_2) - 1 / (2 * nu_sd_z_2)\\\n",
    "                      * (z - nu_mean_z)**2, dim = (1, 2))\n",
    "  return log_q_theta + log_q_z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, x_dim, z_dim, like_dim, n_obs, use_avi = True, hidden_dim = 0,\n",
    "                 const_z = False, mc_samples = 100,\n",
    "                 init_z = False, nu_mean_z_init = torch.empty(0), nu_sd_z_log_init = torch.empty(0),\n",
    "                 init_theta = False, nu_mean_theta_init = torch.empty(0),\n",
    "                 nu_sd_theta_log_init = torch.empty(0),\n",
    "                 use_init_encoder = False):\n",
    "        # NOTE: when using init_z = True, nu_mean_z_init and nu_sd_z_log_init must have\n",
    "        # dimension n_obs * z_dim. When using init_encoder = False, the inits for z should\n",
    "        # have dimension z_dim.\n",
    "\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.use_avi = use_avi\n",
    "        self.const_z = const_z\n",
    "\n",
    "        self.x_dim = x_dim\n",
    "        self.z_dim = z_dim\n",
    "        self.n_obs = n_obs\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.like_dim = like_dim\n",
    "\n",
    "        if (data_set == \"MNIST\"):\n",
    "            # size of weights\n",
    "            self.dim_theta = z_dim * like_dim + like_dim**2 + like_dim * x_dim\n",
    "        if (data_set == \"CIFAR10\" or data_set == \"FashionMNIST\"):\n",
    "            self.dim_theta = z_dim * like_dim + like_dim**2 + like_dim * x_dim\n",
    "\n",
    "        # variational parameters for q(theta)\n",
    "        if (init_theta):\n",
    "            self.nu_mean_theta = torch.nn.Parameter(nu_mean_theta_init)\n",
    "            self.nu_sd_theta_log = torch.nn.Parameter(nu_sd_theta_log_init)\n",
    "        else:\n",
    "            self.nu_mean_theta = torch.nn.Parameter(torch.zeros(self.dim_theta))\n",
    "            self.nu_sd_theta_log = torch.nn.Parameter(torch.zeros(self.dim_theta) - 2)\n",
    "\n",
    "        # variational parameters for q(z)\n",
    "        if (const_z and (not use_avi)):\n",
    "            self.nu_mean_z = torch.nn.Parameter(torch.randn(z_dim))\n",
    "            self.nu_sd_z_log = torch.nn.Parameter(torch.randn(z_dim))\n",
    "        elif (use_avi):\n",
    "            if (use_init_encoder):\n",
    "                self.Encoder = init_encoder(Encoder(x_dim, hidden_dim, z_dim),\n",
    "                                            z_dim, hidden_dim, x_dim,\n",
    "                                            nu_mean_z_init, nu_sd_z_log_init)\n",
    "\n",
    "            self.Encoder = Encoder(x_dim, hidden_dim, z_dim)\n",
    "        else:\n",
    "            if (init_z):\n",
    "                self.nu_mean_z = torch.nn.Parameter(nu_mean_z_init)\n",
    "                self.nu_sd_z_log = torch.nn.Parameter(nu_sd_z_log_init)\n",
    "            else:\n",
    "                self.nu_mean_z = torch.nn.Parameter(torch.randn(n_obs, z_dim))\n",
    "                self.nu_sd_z_log = torch.nn.Parameter(torch.randn(n_obs, z_dim) - 1)\n",
    "        \n",
    "        self.mc_samples = mc_samples\n",
    "        \n",
    "    def reparam(self, nu_mean_z, nu_sd_z, nu_mean_theta, nu_sd_theta, mc_samples):\n",
    "        epsilon = torch.randn((mc_samples, self.n_obs, self.z_dim)).to(device)\n",
    "        z = nu_mean_z + nu_sd_z * epsilon\n",
    "        \n",
    "        epsilon_theta = torch.randn((mc_samples, self.dim_theta)).to(device)\n",
    "        theta = nu_mean_theta + nu_sd_theta * epsilon_theta\n",
    "\n",
    "        return z, theta\n",
    "    \n",
    "    def variational_z(self, x):\n",
    "        if (self.use_avi):\n",
    "            nu_mean_z, nu_sd_z_log = self.Encoder(x)\n",
    "        elif (self.const_z):\n",
    "            nu_mean_z = self.nu_mean_z.repeat((self.n_obs, 1))\n",
    "            nu_sd_z_log = self.nu_sd_z_log.repeat((self.n_obs, 1))\n",
    "        else:\n",
    "            nu_mean_z = self.nu_mean_z\n",
    "            nu_sd_z_log = self.nu_sd_z_log\n",
    "        \n",
    "        return nu_mean_z, nu_sd_z_log\n",
    "    \n",
    "    def compute_elbo(self, x, batch_index, batch_size):\n",
    "        nu_mean_z, nu_sd_z_log = self.variational_z(x)\n",
    "\n",
    "        z, theta = self.reparam(nu_mean_z, torch.exp(nu_sd_z_log),\n",
    "                                self.nu_mean_theta, torch.exp(self.nu_sd_theta_log),\n",
    "                                self.mc_samples)\n",
    "\n",
    "        # only compute p for the z's relevant to the current batch\n",
    "        z_batch = z[:, (batch_index * batch_size):((batch_index + 1) * batch_size), :]\n",
    "\n",
    "        if (data_set == \"MNIST\"):\n",
    "            decoder = Decoder_MNIST(self.z_dim, self.like_dim, self.x_dim).to(device)\n",
    "            p = torch.empty((self.mc_samples, batch_size, self.x_dim)).to(device)\n",
    "\n",
    "            for i in range(self.mc_samples): \n",
    "                decoder = set_weights_MNIST(decoder, theta[i,:], self.z_dim, self.like_dim,\n",
    "                                            self.x_dim)\n",
    "                p[i, :, :] = decoder.forward(z_batch[i, :, :])\n",
    "        \n",
    "            Elbo = log_joint_MNIST(x, p, z_batch, theta)\n",
    "        \n",
    "        if (data_set == \"CIFAR10\" or data_set == \"FashionMNIST\"):\n",
    "            decoder = Decoder_R(self.z_dim, self.like_dim, self.x_dim).to(device)\n",
    "            alpha = torch.empty((self.mc_samples, batch_size, self.x_dim)).to(device)\n",
    "            beta = torch.empty((self.mc_samples, batch_size, self.x_dim)).to(device)\n",
    "\n",
    "            for i in range(self.mc_samples):\n",
    "                decoder = set_weights_R(decoder, theta[i,:], self.z_dim, self.like_dim, self.x_dim)\n",
    "                alpha[i, :, :] = decoder.forward(z_batch[i, :, :])\n",
    "            \n",
    "            beta = torch.ones((self.mc_samples, batch_size, self.x_dim)).to(device)\n",
    "            Elbo = log_joint_R(x, alpha, beta, z_batch, theta)\n",
    "            \n",
    "        Elbo = Elbo - log_q(theta, z_batch, self.nu_mean_theta, torch.square(self.nu_sd_theta_log),\n",
    "                    nu_mean_z, torch.square(nu_sd_z_log))\n",
    "\n",
    "        return torch.mean(Elbo)\n",
    "    \n",
    "    def variational_parameters(self, x):\n",
    "        nu_mean_z, nu_sd_z_log = self.variational_z(x)\n",
    "        return self.nu_mean_theta, self.nu_sd_theta_log, nu_mean_z, nu_sd_z_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Bayesian inference using VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For starters, let's use a relatively small network\n",
    "if (data_set == \"MNIST\"):\n",
    "    x_dim = 784\n",
    "    z_dim = 20  # 200\n",
    "    hidden_dim = 20  # 400\n",
    "    like_dim = 40  # 400\n",
    "    n_obs = batch_size  # NOTE: if using only a subsample, set to batchsize (rather than total n_obs)\n",
    "    n_epochs = 4000 # 1000  # 30\n",
    "\n",
    "if (data_set == \"CIFAR10\" or data_set == \"FashionMNIST\"):\n",
    "    z_dim = 20\n",
    "    hidden_dim = 20\n",
    "    like_dim = 40\n",
    "    n_obs = 60000\n",
    "    batch_size = batch_size\n",
    "    n_epochs = 100\n",
    "\n",
    "if (data_set == \"CIFAR10\"):\n",
    "    x_dim = 32 * 32 * 3\n",
    "elif (data_set == \"FashionMNIST\"):\n",
    "    x_dim = 28 * 28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a subset of the data (i.e. get the first batch and save it as x)\n",
    "for batch_idx, (x, _) in enumerate(train_loader):\n",
    "    x = x.view(batch_size, x_dim)\n",
    "    x = x.to(device)\n",
    "    break\n",
    "\n",
    "n_obs = batch_size  # for experiment adjust batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fvi_diagnose(model, mc_samples = 100):\n",
    "    nu_mean_theta, nu_sd_theta_log, nu_mean_z, nu_sd_z_log = model.variational_parameters(x)\n",
    "\n",
    "    model_benchmark = Model(x_dim, z_dim, like_dim, n_obs, use_avi = False, hidden_dim = 0,\n",
    "                            const_z = False, mc_samples = mc_samples,\n",
    "                            init_z = True, nu_mean_z_init = nu_mean_z, nu_sd_z_log_init = nu_sd_z_log,\n",
    "                            init_theta = True, nu_mean_theta_init = nu_mean_theta,\n",
    "                            nu_sd_theta_log_init = nu_sd_theta_log).to(device)\n",
    "\n",
    "    loss = - model_benchmark.compute_elbo(x, batch_idx, batch_size)\n",
    "    loss.backward()\n",
    "\n",
    "    grads = []\n",
    "    for param in model_benchmark.parameters():\n",
    "        grads.append(param.grad.view(-1) / loss)\n",
    "    grads = torch.cat(grads)\n",
    "\n",
    "    return torch.norm(grads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vi(seed, model, n_epochs, print_output = False, lr = 1e-3):\n",
    "    # Run VI, given a seed and a model, for a specified number of iterations.\n",
    "    # The optimization is divided into three phases of equal length. At the\n",
    "    # beginning of each phase, the learning rate decreases by a factor of 0.1.\n",
    "    #\n",
    "    torch.manual_seed(seed)\n",
    "    optimizer = Adam(model.parameters(), lr = lr)\n",
    "\n",
    "    n_phase = n_epochs // 3\n",
    "\n",
    "    if (print_output):\n",
    "        print(\"Starting training VAE...\")\n",
    "    model.train()  # CHECK -- is this helpful?\n",
    "    loss_saved = np.empty(n_epochs)\n",
    "    index_saved = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "    for i in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss = - model.compute_elbo(x, batch_idx, batch_size)\n",
    "\n",
    "        loss_saved[index_saved] = loss.data\n",
    "        index_saved +=1 \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if ((n_epochs % n_phase == 0) and (n_epochs != 0)):\n",
    "            lr = lr * 0.1\n",
    "\n",
    "        if (print_output and (i % 10 == 0)):\n",
    "            print(\"\\titeration:\", i, \"\\tloss: \", loss.data)\n",
    "\n",
    "            grads = []\n",
    "            for param in model.parameters():\n",
    "                grads.append(param.grad.view(-1) / loss)\n",
    "            grads = torch.cat(grads)\n",
    "            print(\"\\tGradient norm = \", torch.max(grads).data)\n",
    "\n",
    "    end_time = time.time()\n",
    "    run_time = end_time - start_time\n",
    "\n",
    "    fvi_grad = fvi_diagnose(model) \n",
    "   \n",
    "    return model, loss_saved, run_time, fvi_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1954\n",
    "lr = 1e-4\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual runs\n",
    "(This is useful for debugging but not required to get experimental results, which are run in a more systematic way.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_individual = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_individual):\n",
    "    torch.manual_seed(1954)\n",
    "    model = Model(x_dim, z_dim, like_dim, n_obs, use_avi = False, hidden_dim = 0,\n",
    "                mc_samples = 100).to(device)\n",
    "    model, loss_saved, run_time, fvi_grad = run_vi(seed, model, n_epochs, print_output = True, lr = lr)\n",
    "\n",
    "    plt.plot(-loss_saved)\n",
    "    plt.yscale(\"log\")\n",
    "    print(model.nu_mean_z)\n",
    "    print(model.nu_sd_z_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_individual):\n",
    "    # Run F-VI again, this time using a different seed\n",
    "    torch.manual_seed(1989)\n",
    "    model2 = Model(x_dim, z_dim, hidden_dim, n_obs, like_dim, use_avi = False,\n",
    "                mc_samples = 100).to(device)\n",
    "    model2, loss_saved2 = run_vi(seed, model2, n_epochs, print_output = True, lr = lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_individual):\n",
    "    torch.manual_seed(seed)\n",
    "    hidden_dim = 40  # 20\n",
    "    model_avi = Model(x_dim, z_dim, like_dim, n_obs, use_avi = True, hidden_dim = hidden_dim,\n",
    "                mc_samples = 100).to(device)\n",
    "    model_avi, loss_avi_saved, run_time, fvi_grad =\\\n",
    "        run_vi(seed, model_avi, n_epochs, print_output = True, lr = lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_individual):\n",
    "    torch.manual_seed(seed)\n",
    "    hidden_dim = 1\n",
    "    model_avi2 = Model(x_dim, z_dim, like_dim, n_obs, use_avi = True, hidden_dim=hidden_dim,\n",
    "                mc_samples = 100).to(device)\n",
    "    model_avi2, loss_avi2_saved, time_saved, fg_saved =\\\n",
    "        run_vi(seed, model_avi2, n_epochs, print_output = True, lr = lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_individual):\n",
    "    torch.manual_seed(seed)\n",
    "    hidden_dim = 10\n",
    "    model_avi3 = Model(x_dim, z_dim, like_dim, n_obs, use_avi = True, hidden_dim = hidden_dim,\n",
    "                mc_samples = 100).to(device)\n",
    "    model_avi3, loss_avi3_saved, _, _ = run_vi(seed, model_avi3, n_epochs, print_output = True, lr = lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_individual):\n",
    "    torch.manual_seed(seed)\n",
    "    hidden_dim = 15\n",
    "    model_avi4 = Model(x_dim, z_dim, hidden_dim, n_obs, like_dim, use_avi = True,\n",
    "                mc_samples = 100).to(device)\n",
    "    model_avi4, loss_avi4_saved = run_vi(seed, model_avi4, n_epochs, print_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_individual):\n",
    "    torch.manual_seed(seed)\n",
    "    hidden_dim = 100 # 60\n",
    "    model_avi5 = Model(x_dim, z_dim, like_dim, n_obs, use_avi = True, hidden_dim = hidden_dim,\n",
    "                mc_samples = 100).to(device)\n",
    "    model_avi5, loss_avi5_saved, _, _ =\\\n",
    "        run_vi(seed, model_avi5, n_epochs, print_output = True, lr = lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_individual):\n",
    "    nu_mean_theta, nu_sd_theta_log, nu_mean_z, nu_sd_z_log = model_avi2.variational_parameters()\n",
    "    model_init = Model(x_dim, z_dim, like_dim, n_obs, use_avi = False, mc_samples = 100,\n",
    "                    init_z = True, nu_mean_z_init = nu_mean_z,\n",
    "                    nu_sd_z_log_init = nu_sd_z_log,\n",
    "                    init_theta = True, nu_mean_theta_init = nu_mean_theta,\n",
    "                    nu_sd_theta_log_init = nu_sd_theta_log).to(device)\n",
    "\n",
    "    model_init, loss_init_saved, time_saved, fg_grad =\\\n",
    "        run_vi(seed, model_init, n_epochs, print_output = True, lr = lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_individual):\n",
    "    torch.manual_seed(seed)\n",
    "    model_const = Model(x_dim, z_dim, like_dim, n_obs, use_avi = False,\n",
    "                        const_z = True, mc_samples = 100).to(device)\n",
    "    model_const, loss_const_saved, _, _ =\\\n",
    "        run_vi(seed, model_const, n_epochs, print_output = True, lr = lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_individual):\n",
    "    nu_mean_z = model_const.nu_mean_z\n",
    "    nu_sd_z_log = model_const.nu_sd_z_log\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    lr = 1e-5\n",
    "    hidden_dim = 100 # 60\n",
    "    model_avi_init = Model(x_dim, z_dim, like_dim, n_obs, use_avi = True,\n",
    "                    hidden_dim = hidden_dim, mc_samples=100,\n",
    "                    use_init_encoder = True,\n",
    "                    nu_mean_z_init = nu_mean_z,\n",
    "                    nu_sd_z_log_init = nu_sd_z_log).to(device)\n",
    "    model_avi_init, loss_avi_init_saved, _, _ =\\\n",
    "        run_vi(seed, model_avi_init, n_epochs, print_output = True, lr = lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_individual):\n",
    "    n_start = 0\n",
    "    n_end = n_epochs\n",
    "    base = 0\n",
    "    plt.plot(- loss_saved[n_start:n_end] + base, label = 'F-VI', color = \"black\")\n",
    "    # plt.plot(loss_saved2[n_start:n_epochs] + base, label = 'F-VI2', alpha = 0.5)\n",
    "    plt.plot(- loss_avi2_saved[n_start:n_end] + base, label = 'k = 1', alpha = 0.5)\n",
    "    plt.plot(- loss_avi3_saved[n_start:n_end] + base, label = 'k = 10', alpha = 0.5)\n",
    "    #plt.plot(loss_avi4_saved[n_start:n_end] + base, label = 'k = 15', alpha = 0.5)\n",
    "    plt.plot(- loss_avi_saved[n_start:n_end] + base, label = 'k = 40', alpha = 0.5)\n",
    "    plt.plot(- loss_avi5_saved[n_start:n_end] + base, label = 'k = 100', alpha = 0.5)\n",
    "    # plt.plot(- loss_init_saved[n_start:n_end] + base, label = 'F-VI (init)', alpha = 0.5)\n",
    "    plt.plot(- loss_const_saved[n_start:n_end] + base, label = 'Const', color = \"red\")\n",
    "    # plt.plot(- loss_avi_init_saved[n_start:n_end] + base, label = \"k = 100 (init)\", alpha = 0.5)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend(loc = \"best\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run numerical experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(seed, data_set, n_epochs, nn_widths, lr):\n",
    "    # NOTE: the seed is used (i) when initializing the model, and (ii) when running the\n",
    "    # optimizer.\n",
    "\n",
    "    loss_all = np.empty((n_epochs, 3 + nn_widths.size))\n",
    "    saved_times = np.empty(3 + nn_widths.size)\n",
    "    saved_fvi_gradient = np.empty(3 + nn_widths.size)\n",
    "\n",
    "    # Run F-VI\n",
    "    torch.manual_seed(seed)\n",
    "    model = Model(x_dim, z_dim, like_dim, n_obs, use_avi = False).to(device)\n",
    "    _model, loss, time_s, fvi_gradient = run_vi(seed, model, n_epochs, print_output = False, lr = lr)\n",
    "    loss_all[:, 0] = loss\n",
    "    saved_times[0] = time_s\n",
    "    saved_fvi_gradient[0] = fvi_gradient.data\n",
    "\n",
    "    # Run A-VI\n",
    "    for i in range(nn_widths.size):\n",
    "        print(\"\\tRunning widths = \", nn_widths[i])\n",
    "        torch.manual_seed(seed)\n",
    "        model = Model(x_dim, z_dim, like_dim, n_obs, use_avi = True,\n",
    "                      hidden_dim = nn_widths[i]).to(device)\n",
    "        _model, loss, time_s, fvi_gradient = run_vi(seed, model, n_epochs, print_output = False, lr = lr)\n",
    "        loss_all[:, i + 1] = loss\n",
    "        saved_times[i + 1] = time_s\n",
    "        saved_fvi_gradient[i + 1] = fvi_gradient.data\n",
    "\n",
    "        if (i == 0):\n",
    "            best_loss = loss_all[n_epochs - 1, i + 1]\n",
    "            model_best = _model\n",
    "        elif (loss_all[n_epochs - 1, i + 1] <= best_loss):\n",
    "            best_loss = loss_all[n_epochs - 1, i + 1]\n",
    "            model_best = _model\n",
    "    \n",
    "    # Run F-VI with an initialization provided by A-VI (k = 100)\n",
    "    nu_mean_theta, nu_sd_theta_log, nu_mean_z, nu_sd_z_log = model_best.variational_parameters(x)\n",
    "    model = Model(x_dim, z_dim, like_dim, n_obs, use_avi = False,\n",
    "                  init_z = True, nu_mean_z_init = nu_mean_z,\n",
    "                  nu_sd_z_log_init = nu_sd_z_log,\n",
    "                  init_theta = True, nu_mean_theta_init = nu_mean_theta,\n",
    "                  nu_sd_theta_log_init = nu_sd_theta_log).to(device)\n",
    "    _model, loss, time_s, fvi_gradient = run_vi(seed, model, n_epochs, print_output = False, lr = lr)\n",
    "    loss_all[:, nn_widths.size + 1] = loss\n",
    "    saved_times[nn_widths.size + 1] = time_s\n",
    "    saved_fvi_gradient[nn_widths.size + 1] = fvi_gradient.data\n",
    "\n",
    "    # Run A-VI with constant out for inference network\n",
    "    model = Model(x_dim, z_dim, like_dim, n_obs, use_avi = False, const_z = True).to(device)\n",
    "    _model, loss, time_s, fvi_gradient = run_vi(seed, model, n_epochs, print_output=False, lr=lr)\n",
    "    loss_all[:, nn_widths.size + 2] = loss\n",
    "    saved_times[nn_widths.size + 2] = time_s\n",
    "    saved_fvi_gradient[nn_widths.size + 2] = fvi_gradient.data\n",
    "\n",
    "    np.save(\"deliv/vae_\" + data_set + \"_loss_\" + str(seed), loss_all)\n",
    "    np.save(\"deliv/vae_\" + data_set + \"_time_\" + str(seed), saved_times)\n",
    "    np.save(\"deliv/fvi_\" + data_set + \"_gradient_\" + str(seed), saved_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_widths = np.array([1, 10, 40, 80, 100, 120])\n",
    "nn_widths = np.array([1, 10, 20, 40, 80, 120])\n",
    "n_epochs = 500  # 2000 (1000 might be enough)\n",
    "# lr = 1e-5\n",
    "\n",
    "# run_experiment(seed, data_set, n_epochs, nn_widths, lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed:  1954\n",
      "\tRunning widths =  1\n",
      "\tRunning widths =  10\n",
      "\tRunning widths =  20\n",
      "\tRunning widths =  40\n",
      "\tRunning widths =  80\n",
      "\tRunning widths =  120\n",
      "seed:  1955\n",
      "\tRunning widths =  1\n",
      "\tRunning widths =  10\n",
      "\tRunning widths =  20\n",
      "\tRunning widths =  40\n",
      "\tRunning widths =  80\n",
      "\tRunning widths =  120\n",
      "seed:  1956\n",
      "\tRunning widths =  1\n",
      "\tRunning widths =  10\n",
      "\tRunning widths =  20\n",
      "\tRunning widths =  40\n",
      "\tRunning widths =  80\n",
      "\tRunning widths =  120\n",
      "seed:  1957\n",
      "\tRunning widths =  1\n",
      "\tRunning widths =  10\n",
      "\tRunning widths =  20\n",
      "\tRunning widths =  40\n",
      "\tRunning widths =  80\n",
      "\tRunning widths =  120\n",
      "seed:  1958\n",
      "\tRunning widths =  1\n",
      "\tRunning widths =  10\n",
      "\tRunning widths =  20\n",
      "\tRunning widths =  40\n",
      "\tRunning widths =  80\n",
      "\tRunning widths =  120\n",
      "seed:  1959\n",
      "\tRunning widths =  1\n",
      "\tRunning widths =  10\n",
      "\tRunning widths =  20\n",
      "\tRunning widths =  40\n",
      "\tRunning widths =  80\n",
      "\tRunning widths =  120\n",
      "seed:  1960\n",
      "\tRunning widths =  1\n",
      "\tRunning widths =  10\n",
      "\tRunning widths =  20\n",
      "\tRunning widths =  40\n",
      "\tRunning widths =  80\n",
      "\tRunning widths =  120\n",
      "seed:  1961\n",
      "\tRunning widths =  1\n",
      "\tRunning widths =  10\n",
      "\tRunning widths =  20\n",
      "\tRunning widths =  40\n",
      "\tRunning widths =  80\n",
      "\tRunning widths =  120\n",
      "seed:  1962\n",
      "\tRunning widths =  1\n",
      "\tRunning widths =  10\n",
      "\tRunning widths =  20\n",
      "\tRunning widths =  40\n",
      "\tRunning widths =  80\n",
      "\tRunning widths =  120\n",
      "seed:  1963\n",
      "\tRunning widths =  1\n",
      "\tRunning widths =  10\n",
      "\tRunning widths =  20\n",
      "\tRunning widths =  40\n",
      "\tRunning widths =  80\n",
      "\tRunning widths =  120\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4  # for A-VI on CIFAR10, may require a smaller learning rate.\n",
    "init_seed = 1954\n",
    "for i in range(10):\n",
    "    seed = init_seed + i\n",
    "    print(\"seed: \", seed)\n",
    "    run_experiment(seed, data_set, n_epochs, nn_widths, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and analyze experimental results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 500\n",
    "nn_widths = np.array([1, 10, 20, 40, 80, 120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_window(loss, index_center, window):\n",
    "    return np.mean(loss[(index_center - window):(index_center + window)])\n",
    "\n",
    "def sd_window(loss, index_center, window):\n",
    "    return np.std(loss[(index_center - window):(index_center + window)])\n",
    "\n",
    "window = 10\n",
    "index_center = n_epochs - window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo max:  [5.04399973e+17 1.01117661e+18 6.02057902e+17 2.94839370e+18\n",
      " 4.15585126e+18 9.22298583e+18 6.64609740e+18 1.98181110e+19\n",
      " 9.65803873e+14]\n",
      "Elbo silver:  1.9818110995989213e+19\n"
     ]
    }
   ],
   "source": [
    "# Get results across multiple seeds\n",
    "# For FashionMNIST, init_seed is 1789\n",
    "# For MNIST, init_seed is 1954\n",
    "# For CIFAR10, init_seed is 1963\n",
    "\n",
    "data_set = \"FashionMNIST\"\n",
    "init_seed = 1789\n",
    "num_seed = 10\n",
    "num_algorithms = nn_widths.size + 3\n",
    "n_epochs = 500\n",
    "\n",
    "Elbo_final = np.empty((num_seed, num_algorithms))\n",
    "\n",
    "for i in range(num_seed):\n",
    "    loss_all = np.load(\"deliv/vae_\" + data_set + \"_loss_\" + str(init_seed + i) + \".npy\")\n",
    "\n",
    "    for j in range(num_algorithms):\n",
    "        Elbo_final[i, j] = mean_window(loss_all[:,j], n_epochs - window, window)\n",
    "\n",
    "# Get the best (non-nan) Elbo estimate obtained with \n",
    "Elbo_silver = - np.nanmin(Elbo_final[:, nn_widths.size + 1])\n",
    "\n",
    "# Get the optimal Elbo returned by all algorithms\n",
    "Elbo_max = - np.nanmin(Elbo_final, axis = 0)\n",
    "print(\"Elbo max: \", Elbo_max)\n",
    "\n",
    "print(\"Elbo silver: \", Elbo_silver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3493474/1543660394.py:1: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-white')  # seaborn-v0_8-white\n"
     ]
    }
   ],
   "source": [
    "plt.style.use('seaborn-white')  # seaborn-v0_8-white\n",
    "\n",
    "params = {'axes.labelsize': 18,'axes.titlesize':25, 'legend.fontsize': 15, 'xtick.labelsize': 15,\n",
    "          'ytick.labelsize': 15}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "linewidth = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Elbo_median = - np.nanmedian(Elbo_final, axis = 0)\n",
    "Elbo_min = - np.nanmax(Elbo_final, axis = 0)\n",
    "\n",
    "linewidth = 2\n",
    "\n",
    "plt.axhline(y = Elbo_silver, linewidth = linewidth, color = 'black', linestyle = \"dotted\",\n",
    "           label = \"ELBO*\")\n",
    "\n",
    "plt.plot(nn_widths, Elbo_median[1:7], \"-o\", label = \"A-VI\", color = \"royalblue\")\n",
    "plt.fill_between(nn_widths, Elbo_max[1:7], Elbo_min[1:7], alpha = 0.5, color = \"royalblue\")\n",
    "\n",
    "plt.plot(nn_widths, np.repeat(Elbo_median[0], 6), linewidth = linewidth, color = 'black', label = \"F-VI\")\n",
    "plt.fill_between(nn_widths, np.repeat(Elbo_min[0], 6), np.repeat(Elbo_max[0], 6), alpha = 0.25,\n",
    "                 color = \"black\")\n",
    "\n",
    "plot_constant = True\n",
    "\n",
    "if(plot_constant):\n",
    "    plt.plot(nn_widths, np.repeat(Elbo_median[8], 6), label = \"Const.\")\n",
    "    plt.fill_between(nn_widths, Elbo_max[8], Elbo_min[8], alpha = 0.25)\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.grid(which = 'major', visible = 'true', c = 'grey', alpha = 0.25)\n",
    "plt.xlabel(\"k\")\n",
    "if (data_set == \"MNIST\"):\n",
    "    plt.ylabel(\"ELBO\")\n",
    "plt.title(data_set)\n",
    "if (data_set == \"FashionMNIST\"):\n",
    "    plt.legend(loc = \"lower right\", bbox_to_anchor=(1.3, 0.5))\n",
    "    plt.ylim(1e13, 3e19)\n",
    "\n",
    "\n",
    "plt.savefig(\"to_discuss/k_vae_\" + data_set + \".pdf\", bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine a specific seed for example plot\n",
    "seed = 1968\n",
    "data_set = \"FashionMNIST\"  # Options: MNIST, FashionMNIST, CIRFAR10\n",
    "loss_all = np.load(\"deliv/vae_\" + data_set + \"_loss_\" + str(seed) + \".npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "plotted_widths = np.array([10, 40, 80])\n",
    "# nn_widths = np.array([1, 10, 20, 40, 80, 120])\n",
    "\n",
    "n_start = 0\n",
    "\n",
    "# ax.plot(- loss_all[n_start:, nn_widths.size + 1], label = \"AF-VI\", color = 'black',\n",
    "#         linestyle = \"dashed\", linewidth = linewidth)\n",
    "\n",
    "ax.axhline(y = Elbo_silver, linewidth = linewidth, color = 'black', linestyle = \"dotted\",\n",
    "           label = \"ELBO*\")\n",
    "\n",
    "ax.plot(-loss_all[n_start:, 0], label = 'F-VI', linewidth = linewidth, color = 'black')\n",
    "\n",
    "\n",
    "ax.plot(-loss_all[n_start:, nn_widths.size + 2], label = \"Const\", color = \"red\",\n",
    "        linewidth = linewidth)\n",
    "\n",
    "nn_widths = np.array([1, 10, 20, 40, 80, 120])\n",
    "for i in range(nn_widths.size):\n",
    "    if (nn_widths[i] in plotted_widths):\n",
    "        ax.plot(- loss_all[n_start:, i + 1], label = \"k = \" + str(nn_widths[i]), alpha = 0.5,\n",
    "        linewidth = linewidth)\n",
    "\n",
    "plt.grid(which = 'major', visible = 'true', c = 'grey', alpha = 0.25)\n",
    "plt.legend(loc = \"lower right\", ncols = 2, bbox_to_anchor=(1.025, -0.04))\n",
    "# plt.ylim(10**1, 1 * 10**19)\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"VAE \" + data_set)\n",
    "\n",
    "plt.savefig(\"to_discuss/elbo_vae_\" + data_set + \"_\" + str(seed) + \".pdf\", bbox_inches = 'tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silver:  -1.916481070865192e+19  +/-  1.3551668232630513e+18\n",
      "FVI:  -1.4343688474979206e+16  +/-  8321339449737356.0\n",
      "Const:  -965815298403860.5  +/-  1389057317300.9983\n",
      "k = 1:  -4.4422675871549094e+17  +/-  8321339449737356.0\n",
      "k = 10:  -1.736477394706891e+17  +/-  3.778198812129833e+16\n",
      "k = 20:  -2.6109344666148144e+17  +/-  1.921753083796226e+16\n",
      "k = 40:  -8.440083323917487e+17  +/-  3.859208973807375e+16\n",
      "k = 80:  -7.530952081576905e+18  +/-  7.869393942158878e+16\n",
      "k = 120:  -6.128665710349181e+18  +/-  1.0217704987858893e+18\n"
     ]
    }
   ],
   "source": [
    "# Get asymptotic ELBO\n",
    "print(\"Silver: \", mean_window(loss_all[:, nn_widths.size + 1], index_center, window), \" +/- \",\n",
    "      sd_window(loss_all[:, nn_widths.size + 1], index_center, window))\n",
    "\n",
    "print(\"FVI: \", mean_window(loss_all[:, 0], index_center, window), \" +/- \",\n",
    "      sd_window(loss_all[:, 0], index_center, window))\n",
    "\n",
    "print(\"Const: \", mean_window(loss_all[:, nn_widths.size + 2], index_center, window), \" +/- \",\n",
    "      sd_window(loss_all[:, nn_widths.size + 2], index_center, window))\n",
    "\n",
    "for i in range(nn_widths.size):\n",
    "  print(\"k = \" + str(nn_widths[i]) + \": \", mean_window(loss_all[:, i + 1],\n",
    "        index_center, window), \" +/- \",\n",
    "        sd_window(loss_all[:, i], index_center, window))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b7e68a6523d9654d119e3ab45bb2c5c51f02effa6643d52b99addcee48c066f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
